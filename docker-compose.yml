version: "3.8"
services:
    inference:
        container_name: "semantic-segment-inference"
        build: "./inference"
        ports:
            - '8000:8000'
        command: "python3 main.py"
        deploy:
            resources:
                reservations:
                    devices:
                        - capabilities: [gpu]

    train:
        container_name: "semantic-segment-train"
        build: "./train"
        ports:
            - '5000:5000'
        command: "python3 main.py"
        environment:
            - RESPONSE_URL=
        deploy:
            resources:
                reservations:
                    devices:
                        - capabilities: [gpu]