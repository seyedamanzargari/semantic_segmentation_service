version: "3.8"
services:
    inference:
        network_mode: host
        container_name: "semantic-segment-inference"
        build: "./inference"
        command: "python3 main.py"
        # ports:
        #     - "5553:5553"
        volumes:
            - ./weights:/weights

        environment:
            - PORT=5556
        deploy:
            resources:
                reservations:
                    devices:
                        - capabilities: [gpu]

    train:
        network_mode: host
        container_name: "semantic-segment-train"
        build: "./train"
        command: "python3 main.py"
        # ports:
        #     - "5554:5554"
        volumes:
            -   ./weights:/weights
            -   ./dataset:/dataset
        environment:
            - RESPONSE_URL=http://127.0.0.1:8000/api/v1/train/done
            - LOGGER_URL=http://127.0.0.1:8000/logger
            - PORT=5554
            - IS_LOGGER_ON=False
        deploy:
            resources:
                reservations:
                    devices:
                        - capabilities: [gpu]